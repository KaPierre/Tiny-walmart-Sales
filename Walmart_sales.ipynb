{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Walmart : predict weekly sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.8/site-packages (5.5.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from plotly) (8.0.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from plotly) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) # to avoid deprecation warnings\n",
    "\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "# setting Jedha color palette as default\n",
    "pio.templates[\"jedha\"] = go.layout.Template(\n",
    "    layout_colorway=[\"#4B9AC7\", \"#4BE8E0\", \"#9DD4F3\", \"#97FBF6\", \"#2A7FAF\", \"#23B1AB\", \"#0E3449\", \"#015955\"]\n",
    ")\n",
    "pio.templates.default = \"jedha\"\n",
    "pio.renderers.default = \"iframe_connected\" # to be replaced by \"iframe\" if working on JULIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "walmart = pd.read_csv(\"Walmart_Store_sales.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Holiday_Flag</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>18-02-2011</td>\n",
       "      <td>1572117.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.61</td>\n",
       "      <td>3.045</td>\n",
       "      <td>214.777523</td>\n",
       "      <td>6.858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.0</td>\n",
       "      <td>25-03-2011</td>\n",
       "      <td>1807545.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.38</td>\n",
       "      <td>3.435</td>\n",
       "      <td>128.616064</td>\n",
       "      <td>7.470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.0</td>\n",
       "      <td>27-07-2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130.719581</td>\n",
       "      <td>5.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1244390.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>214.556497</td>\n",
       "      <td>7.346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>28-05-2010</td>\n",
       "      <td>1644470.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.89</td>\n",
       "      <td>2.759</td>\n",
       "      <td>212.412888</td>\n",
       "      <td>7.092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store        Date  Weekly_Sales  Holiday_Flag  Temperature  Fuel_Price  \\\n",
       "0    6.0  18-02-2011    1572117.54           NaN        59.61       3.045   \n",
       "1   13.0  25-03-2011    1807545.43           0.0        42.38       3.435   \n",
       "2   17.0  27-07-2012           NaN           0.0          NaN         NaN   \n",
       "3   11.0         NaN    1244390.03           0.0        84.57         NaN   \n",
       "4    6.0  28-05-2010    1644470.66           0.0        78.89       2.759   \n",
       "\n",
       "          CPI  Unemployment  \n",
       "0  214.777523         6.858  \n",
       "1  128.616064         7.470  \n",
       "2  130.719581         5.936  \n",
       "3  214.556497         7.346  \n",
       "4  212.412888         7.092  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "walmart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Holiday_Flag</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>132</td>\n",
       "      <td>1.360000e+02</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>135.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>19-10-2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.866667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.249536e+06</td>\n",
       "      <td>0.079710</td>\n",
       "      <td>61.398106</td>\n",
       "      <td>3.320853</td>\n",
       "      <td>179.898509</td>\n",
       "      <td>7.598430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.231191</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.474630e+05</td>\n",
       "      <td>0.271831</td>\n",
       "      <td>18.378901</td>\n",
       "      <td>0.478149</td>\n",
       "      <td>40.274956</td>\n",
       "      <td>1.577173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.689290e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>2.514000</td>\n",
       "      <td>126.111903</td>\n",
       "      <td>5.143000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.050757e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.587500</td>\n",
       "      <td>2.852250</td>\n",
       "      <td>131.970831</td>\n",
       "      <td>6.597500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.261424e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62.985000</td>\n",
       "      <td>3.451000</td>\n",
       "      <td>197.908893</td>\n",
       "      <td>7.470000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.806386e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>76.345000</td>\n",
       "      <td>3.706250</td>\n",
       "      <td>214.934616</td>\n",
       "      <td>8.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.771397e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>91.650000</td>\n",
       "      <td>4.193000</td>\n",
       "      <td>226.968844</td>\n",
       "      <td>14.313000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Store        Date  Weekly_Sales  Holiday_Flag  Temperature  \\\n",
       "count   150.000000         132  1.360000e+02    138.000000   132.000000   \n",
       "unique         NaN          85           NaN           NaN          NaN   \n",
       "top            NaN  19-10-2012           NaN           NaN          NaN   \n",
       "freq           NaN           4           NaN           NaN          NaN   \n",
       "mean      9.866667         NaN  1.249536e+06      0.079710    61.398106   \n",
       "std       6.231191         NaN  6.474630e+05      0.271831    18.378901   \n",
       "min       1.000000         NaN  2.689290e+05      0.000000    18.790000   \n",
       "25%       4.000000         NaN  6.050757e+05      0.000000    45.587500   \n",
       "50%       9.000000         NaN  1.261424e+06      0.000000    62.985000   \n",
       "75%      15.750000         NaN  1.806386e+06      0.000000    76.345000   \n",
       "max      20.000000         NaN  2.771397e+06      1.000000    91.650000   \n",
       "\n",
       "        Fuel_Price         CPI  Unemployment  \n",
       "count   136.000000  138.000000    135.000000  \n",
       "unique         NaN         NaN           NaN  \n",
       "top            NaN         NaN           NaN  \n",
       "freq           NaN         NaN           NaN  \n",
       "mean      3.320853  179.898509      7.598430  \n",
       "std       0.478149   40.274956      1.577173  \n",
       "min       2.514000  126.111903      5.143000  \n",
       "25%       2.852250  131.970831      6.597500  \n",
       "50%       3.451000  197.908893      7.470000  \n",
       "75%       3.706250  214.934616      8.150000  \n",
       "max       4.193000  226.968844     14.313000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "walmart.describe(include = 'all') #Dataset description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Store            0\n",
       "Date            18\n",
       "Weekly_Sales    14\n",
       "Holiday_Flag    12\n",
       "Temperature     18\n",
       "Fuel_Price      14\n",
       "CPI             12\n",
       "Unemployment    15\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "walmart.isna().sum() #Counting missing values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    127\n",
       "1.0     11\n",
       "Name: Holiday_Flag, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "walmart['Holiday_Flag'].value_counts() #Looking at holiday flag column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "walmart.drop('Holiday_Flag', axis = 1, inplace = True) #As Holiday flag column is mostly null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Store            0.000000\n",
       "Date            12.000000\n",
       "Weekly_Sales     9.333333\n",
       "Temperature     12.000000\n",
       "Fuel_Price       9.333333\n",
       "CPI              8.000000\n",
       "Unemployment    10.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(100*walmart.isna().sum()/walmart.shape[0]) #Getting proportions of missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing dates will be dropped since we are looking for informations where date is a critical parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Store            0\n",
       "Date             0\n",
       "Weekly_Sales    14\n",
       "Temperature     14\n",
       "Fuel_Price      13\n",
       "CPI             10\n",
       "Unemployment    12\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "walmart.dropna(subset = ['Date'], axis = 0, how = 'all', inplace =True)\n",
    "walmart.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's make sure it's chronological.\n",
    "walmart[\"Date\"] = pd.to_datetime(walmart[\"Date\"])\n",
    "walmart = walmart.sort_values(by=\"Date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's look at our target : Weekly Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_11.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "px.histogram(data_frame= walmart, x = 'Date' , y = 'Weekly_Sales', \n",
    "             color = 'Store',\n",
    "             nbins = 60,\n",
    "            title = 'Weekly Sales by Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We could have drop lines where weekly sales values are missing but as we don't have that many rows, we will fill missing values by mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_mean = walmart['Weekly_Sales'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing missing values by sales mean.\n",
    "walmart['Weekly_Sales'] = walmart['Weekly_Sales'].fillna(sales_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 132 entries, 14 to 22\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   Store         132 non-null    float64       \n",
      " 1   Date          132 non-null    datetime64[ns]\n",
      " 2   Weekly_Sales  132 non-null    float64       \n",
      " 3   Temperature   118 non-null    float64       \n",
      " 4   Fuel_Price    119 non-null    float64       \n",
      " 5   CPI           122 non-null    float64       \n",
      " 6   Unemployment  120 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(6)\n",
      "memory usage: 8.2 KB\n"
     ]
    }
   ],
   "source": [
    "walmart.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping outlayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unemployment outlayers\n",
    "mask = walmart['Weekly_Sales'] < (walmart['Weekly_Sales'].mean() + 3*walmart['Weekly_Sales'].std()) #3 standard deviations\n",
    "walmart = walmart.loc[mask,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop temperature outlayers\n",
    "mask1 = walmart['Temperature'] < (walmart['Temperature'].mean() + 3*walmart['Temperature'].std()) \n",
    "walmart = walmart.loc[mask1,:]\n",
    "\n",
    "#Drop fuelprice outlayers\n",
    "mask2 = walmart['Fuel_Price'] < (walmart['Fuel_Price'].mean() + 3*walmart['Fuel_Price'].std())\n",
    "walmart = walmart.loc[mask2,:]\n",
    "\n",
    "#Drop cpi outlayers\n",
    "mask3 = walmart['CPI'] < (walmart['CPI'].mean() + 3*walmart['CPI'].std())\n",
    "walmart = walmart.loc[mask3,:]\n",
    "\n",
    "#Drop unemployment outlayers\n",
    "mask3 = walmart['Unemployment'] < (walmart['Unemployment'].mean() + 3*walmart['Unemployment'].std())\n",
    "walmart = walmart.loc[mask3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 88 entries, 14 to 22\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   Store         88 non-null     float64       \n",
      " 1   Date          88 non-null     datetime64[ns]\n",
      " 2   Weekly_Sales  88 non-null     float64       \n",
      " 3   Temperature   88 non-null     float64       \n",
      " 4   Fuel_Price    88 non-null     float64       \n",
      " 5   CPI           88 non-null     float64       \n",
      " 6   Unemployment  88 non-null     float64       \n",
      "dtypes: datetime64[ns](1), float64(6)\n",
      "memory usage: 5.5 KB\n"
     ]
    }
   ],
   "source": [
    "walmart.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "walmart = walmart.drop('Date', axis = 1) #We won't use date column to train our model\n",
    "walmart = walmart.drop('Store', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 88 entries, 14 to 22\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Weekly_Sales  88 non-null     float64\n",
      " 1   Temperature   88 non-null     float64\n",
      " 2   Fuel_Price    88 non-null     float64\n",
      " 3   CPI           88 non-null     float64\n",
      " 4   Unemployment  88 non-null     float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 4.1 KB\n"
     ]
    }
   ],
   "source": [
    "walmart.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Weekly_Sales    0\n",
       "Temperature     0\n",
       "Fuel_Price      0\n",
       "CPI             0\n",
       "Unemployment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "walmart.isna().sum() #No more missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some more visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"820px\"\n",
       "    height=\"620\"\n",
       "    src=\"iframe_figures/figure_52.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = make_subplots(rows=3, cols=1, subplot_titles=(\"Unemployment\", \"Fuel price\",  \"Temperature\"))\n",
    "\n",
    "fig.add_trace(go.Scatter(x = walmart['Unemployment'], y = walmart['Weekly_Sales'], mode='markers',), row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Histogram(x = walmart['Fuel_Price'], y = walmart['Weekly_Sales'], nbinsx = 20), row=2, col=1)\n",
    "\n",
    "fig.add_trace(go.Histogram(x = walmart['Temperature'], y = walmart['Weekly_Sales'], nbinsx = 15), row=3, col=1)\n",
    "\n",
    "fig.update_layout(height=600, width=800, title_text=\"Unemployment, Fuel price and Temp impact on Sales\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separating labels from features...\n",
      "...Done.\n",
      "14    8.292073e+05\n",
      "20    5.611451e+05\n",
      "99    2.018315e+06\n",
      "47    1.549019e+06\n",
      "84    1.257271e+06\n",
      "Name: Weekly_Sales, dtype: float64\n",
      "\n",
      "    Temperature  Fuel_Price         CPI  Unemployment\n",
      "14        60.07       2.853  126.234600         6.885\n",
      "20        38.26       2.725  189.704822         8.963\n",
      "99        78.82       2.814  126.139200         7.951\n",
      "47        66.25       2.958  132.521867         8.099\n",
      "84        76.14       2.577  214.894576         6.315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Separating labels from features...\")\n",
    "target_name = 'Weekly_Sales'\n",
    "Y = walmart.loc[:,target_name]\n",
    "X = walmart.loc[:,[c for c in walmart.columns if c!=target_name]] # All columns are kept, except the target\n",
    "print(\"...Done.\")\n",
    "print(Y.head())\n",
    "print()\n",
    "print(X.head())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=10)\n",
    "print(\"...Done.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting pandas DataFrames to numpy arrays...\n",
      "...Done\n",
      "[[ 69.8         4.069     134.8551613   7.658    ]\n",
      " [ 33.26        3.789     133.9587419   7.771    ]\n",
      " [ 76.14        2.577     214.894576    6.315    ]\n",
      " [ 50.49        2.854     204.201755    8.187    ]\n",
      " [ 39.3         3.936     197.7227385   8.09     ]]\n",
      "[[ 48.29        3.75      197.4133259   6.162    ]\n",
      " [ 43.95        3.828     192.831317    6.339    ]]\n",
      "\n",
      "[ 695396.19       1266564.94       1257271.13991525 1257271.13991525\n",
      "  457340.06      ]\n",
      "[485095.41 435397.19]\n"
     ]
    }
   ],
   "source": [
    "print(\"Converting pandas DataFrames to numpy arrays...\")\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "Y_train = Y_train.values\n",
    "Y_test = Y_test.values\n",
    "print(\"...Done\")\n",
    "\n",
    "print(X_train[0:5,:])\n",
    "print(X_test[0:2,:])\n",
    "print()\n",
    "print(Y_train[0:5])\n",
    "print(Y_test[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = StandardScaler(copy = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.50142409  1.48517414 -1.43708884  0.31879626]\n",
      " [-1.5318023   0.95639122 -1.46144204  0.43961562]\n",
      " [ 0.85420612 -1.33248343  0.73735706 -1.11713655]\n",
      " [-0.57305871 -0.80936604  0.44686317  0.88440196]\n",
      " [-1.19571342  1.23400225  0.27084651  0.78068976]]\n"
     ]
    }
   ],
   "source": [
    "preprocessor.fit_transform(X_train)\n",
    "print(X_train[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.69547519  0.88273931  0.26244064 -1.28072383]\n",
      " [-0.93696951  1.03004312  0.13796034 -1.0914758 ]\n",
      " [ 0.30388841 -0.61296095 -1.5004779   0.79031254]\n",
      " [ 1.3594523  -1.25316599  0.64696448  0.45672279]\n",
      " [ 1.23147144  0.51259127  0.85079694 -0.99952477]]\n"
     ]
    }
   ],
   "source": [
    "preprocessor.transform(X_test)\n",
    "print(X_test[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training - testing basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "...Done.\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "print(\"Training model...\")\n",
    "regressor = LinearRegression() \n",
    "regressor.fit(X_train, Y_train)\n",
    "print(\"...Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on training set...\n",
      "[1298068.79925654 1307301.34261346 1006982.88240021 1170066.85930128\n",
      " 1096159.34973289]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions on training set\n",
    "print(\"Predictions on training set...\")\n",
    "Y_train_pred = regressor.predict(X_train)\n",
    "print(Y_train_pred[0:5])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on test set...\n",
      "[ 950021.3714478   973224.03366774 1426024.74181034 1149910.59428076\n",
      "  932449.71776439]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions on test set\n",
    "print(\"Predictions on test set...\")\n",
    "Y_test_pred = regressor.predict(X_test)\n",
    "print(Y_test_pred[0:5])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2-score on train set :  0.07003413474649633\n",
      "R2-score on test set :  0.06038930095476669\n"
     ]
    }
   ],
   "source": [
    "print(\"R2-score on train set : \",r2_score(Y_train, Y_train_pred))\n",
    "print(\"R2-score on test set : \", r2_score(Y_test, Y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Temperature</th>\n",
       "      <td>12250.547124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fuel_Price</th>\n",
       "      <td>-39846.287851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CPI</th>\n",
       "      <td>-133865.059061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unemployment</th>\n",
       "      <td>81200.564583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Coefficients\n",
       "Temperature    12250.547124\n",
       "Fuel_Price    -39846.287851\n",
       "CPI          -133865.059061\n",
       "Unemployment   81200.564583"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here are the correlation coefficients\n",
    "coef = pd.DataFrame(data = regressor.coef_, index = X.columns, columns=['Coefficients'])\n",
    "coef\n",
    "#What we ca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Done.\n",
      "Best hyperparameters :  {'alpha': 1000}\n",
      "Best R2 score :  -0.005467568076498693\n"
     ]
    }
   ],
   "source": [
    "# Perform 3-fold cross-validation to evaluate the generalized R2 score obtained with a Ridge model\n",
    "ridge = Ridge()\n",
    "\n",
    "params = {\n",
    "    'alpha': [10**a for a in range(100)] # 0 corresponds to no regularization\n",
    "}\n",
    "gridsearch = GridSearchCV(ridge, param_grid = params, cv = KFold(n_splits=3, shuffle=True, random_state=2)) # cv : the number of folds to be used for CV, we use Kfold here to shuffle the dataset\n",
    "gridsearch.fit(X_train, Y_train)\n",
    "\n",
    "print(\"...Done.\")\n",
    "print(\"Best hyperparameters : \", gridsearch.best_params_)\n",
    "print(\"Best R2 score : \", gridsearch.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The model gives bad predictions. We could collect more data to improve predictions. In this case, when performing Gridsearch cross validation, shuffling was necessary to optimize scores (lowering the bias)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
